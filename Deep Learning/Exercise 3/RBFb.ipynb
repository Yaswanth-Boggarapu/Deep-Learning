{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec142519-66fa-48f9-b14f-1a8e0555533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "class RBFLayer(keras.layers.Layer):\n",
    "    def __init__(self,hidden_dim,s):\n",
    "        super(RBFLayer, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.s = s\n",
    "        self.centers = self.add_weight(name='centers',\n",
    "                                       shape=(self.hidden_dim,10),\n",
    "                                       initializer='uniform',\n",
    "                                       trainable=True)\n",
    "    def formula(self,x,y):\n",
    "        return torch.exp(-self.s * (x - y).pow(2).sum(dim=1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        a = self.formula(x, self.centers)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7049e7e6-2afe-450a-9586-9aaa1e5520aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['centers:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['centers:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "4/4 [==============================] - 3s 16ms/step - loss: 0.7952\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7885\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7817\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7752\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7688\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7633\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7578\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7527\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7473\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c570877d00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    Dense(10, input_shape=(2,), activation='relu'),\n",
    "    RBFLayer(10,0.02),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "import numpy as np\n",
    "X = np.random.randn(100, 2)\n",
    "y = (X[:, 0] * X[:, 1] > 0).astype(float)\n",
    "\n",
    "model.fit(X, y, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "257e0489-13ca-4404-b63a-0cea5aee579b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 2s 3ms/step - loss: 0.7329\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7261\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7207\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7157\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7113\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7072\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7042\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7010\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6983\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c571e3dd00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define the RBF layer\n",
    "class RBFLayer(keras.layers.Layer):\n",
    "    def __init__(self, units, gamma, **kwargs):\n",
    "        super(RBFLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.centers = self.add_weight(name='centers',\n",
    "                                       shape=(self.units, input_shape[1]),\n",
    "                                       initializer='uniform',\n",
    "                                       trainable=True)\n",
    "        super(RBFLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        diff = tf.expand_dims(inputs, axis=1) - self.centers\n",
    "        squared_diff = tf.reduce_sum(tf.square(diff), axis=-1)\n",
    "        return tf.exp(-self.gamma * squared_diff)\n",
    "\n",
    "# Build the model with the RBF layer\n",
    "model = keras.Sequential([\n",
    "    Dense(10, input_shape=(2,), activation='relu'),\n",
    "    RBFLayer(10, gamma=0.1),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with binary cross-entropy loss and Adam optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# Generate some sample data\n",
    "import numpy as np\n",
    "X = np.random.randn(100, 2)\n",
    "y = (X[:, 0] * X[:, 1] > 0).astype(float)\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=10, batch_size=32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
