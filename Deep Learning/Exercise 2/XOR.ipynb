{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "Xs = torch.Tensor([[-1., -1.],\n",
    "               [-1., 1.],\n",
    "               [1., -1.],\n",
    "               [1., 1.]])\n",
    "\n",
    "y = torch.Tensor([-1., 1., 1., -1.]).reshape(Xs.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XOR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XOR, self).__init__()\n",
    "        self.linear = nn.Linear(2, 2)\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "      x = self.linear(input)\n",
    "      sig = self.Sigmoid(x)\n",
    "      yh = self.linear2(sig)\n",
    "      return yh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 completed\n",
      "Epoch: 500 completed\n"
     ]
    }
   ],
   "source": [
    "xor_network = XOR()\n",
    "epochs = 1000\n",
    "mseloss = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(xor_network.parameters(), lr = 0.03, momentum=0.08)\n",
    "all_losses = []\n",
    "current_loss = 0\n",
    "plot_every = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "  # input training example and return the prediction\n",
    "  yhat = xor_network.forward(Xs)\n",
    "\n",
    "  # calculate MSE loss\n",
    "  loss = mseloss(yhat, y)\n",
    "  \n",
    "  # backpropogate through the loss gradiants\n",
    "  loss.backward()\n",
    "\n",
    "  # update model weights\n",
    "  optimizer.step()\n",
    "\n",
    "  # remove current gradients for next iteration\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  # append to loss\n",
    "  current_loss += loss\n",
    "  if epoch % plot_every == 0:\n",
    "      all_losses.append(current_loss / plot_every)\n",
    "      current_loss = 0\n",
    "  \n",
    "  # print progress\n",
    "  if epoch % 500 == 0:\n",
    "    print(f'Epoch: {epoch} completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear.weight tensor([[-0.5961, -0.2595],\n",
      "        [ 1.2398,  1.1904]])\n",
      "linear.bias tensor([0.5060, 1.2370])\n",
      "linear2.weight tensor([[0.0626, 1.4176]])\n",
      "linear2.bias tensor([-0.2996])\n"
     ]
    }
   ],
   "source": [
    "# show weights and bias\n",
    "for name, param in xor_network.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], grad_fn=<RoundBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# test input\n",
    "input = torch.tensor([1., 1.])\n",
    "out = xor_network(input)\n",
    "print(out.round())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc07d24e2f18896857f0b2a651fe84ba40ce7b297e58d8804a308c8039f752a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
