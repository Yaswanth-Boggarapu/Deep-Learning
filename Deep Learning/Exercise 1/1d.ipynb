{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "torch.Size([120, 4]) torch.Size([30, 4]) torch.Size([120]) torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, Y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, stratify=Y, random_state=123)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = torch.tensor(X_train, dtype=torch.float32),torch.tensor(X_test, dtype=torch.float32),torch.tensor(Y_train, dtype=torch.long),torch.tensor(Y_test, dtype=torch.long)\n",
    "\n",
    "samples, features = X_train.shape\n",
    "classes = Y_test.unique()\n",
    "print(features)\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/ std\n",
    "X_test = (X_test - mean)/ std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class PercepClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PercepClassifier, self).__init__()\n",
    "        self.first_layer = nn.Linear(features, 5)\n",
    "        self.second_layer = nn.Linear(5, 10)\n",
    "        self.third_layer = nn.Linear(10, 15)\n",
    "        self.fourth_layer = nn.Linear(15, 20)\n",
    "        self.final_layer = nn.Linear(20,3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, X_batch):\n",
    "        layer_out = self.relu(self.first_layer(X_batch))\n",
    "        layer_out = self.relu(self.second_layer(layer_out))\n",
    "        layer_out = self.relu(self.third_layer(layer_out))\n",
    "        layer_out = self.relu(self.fourth_layer(layer_out))\n",
    "\n",
    "        return self.softmax(self.final_layer(layer_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2656, 0.3754, 0.3590],\n",
       "        [0.2644, 0.3744, 0.3612],\n",
       "        [0.2603, 0.3772, 0.3626],\n",
       "        [0.2673, 0.3761, 0.3566],\n",
       "        [0.2664, 0.3754, 0.3582]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = PercepClassifier()\n",
    "preds = classifier(X_train[:5])\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(model, loss_func, optimizer, X, Y, epochs=500):\n",
    "    for i in range(epochs):\n",
    "        preds = model(X)\n",
    "        loss = loss_func(preds, Y)\n",
    "        optimizer.zero_grad() \n",
    "        optimizer.step() \n",
    "        if i % 100 == 0: \n",
    "            print(\"NegLogLoss : {:.2f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NegLogLoss : -0.33\n",
      "NegLogLoss : -0.33\n",
      "NegLogLoss : -0.33\n",
      "NegLogLoss : -0.33\n",
      "NegLogLoss : -0.33\n",
      "NegLogLoss : -0.33\n",
      "NegLogLoss : -0.33\n",
      "NegLogLoss : -0.33\n",
      "NegLogLoss : -0.33\n",
      "NegLogLoss : -0.33\n",
      "NegLogLoss : -0.33\n",
      "NegLogLoss : -0.33\n",
      "NegLogLoss : -0.33\n",
      "NegLogLoss : -0.33\n",
      "NegLogLoss : -0.33\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adamax\n",
    "torch.manual_seed(42)\n",
    "epochs = 1500\n",
    "learning_rate = torch.tensor(1/1e2) # 0.01\n",
    "\n",
    "classifier = PercepClassifier()\n",
    "nll_loss = nn.NLLLoss()\n",
    "optimizer = Adamax(params=classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "TrainModel(classifier, nll_loss, optimizer, X_train, Y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 2, 2, 2, 2]), tensor([2, 2, 2, 2, 2]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = classifier(X_test) \n",
    "\n",
    "test_preds = torch.argmax(test_preds, axis=1) \n",
    "\n",
    "train_preds = classifier(X_train)\n",
    "\n",
    "train_preds = torch.argmax(train_preds, axis=1) \n",
    "\n",
    "test_preds[:5], train_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.33\n",
      "Test  Accuracy : 0.33\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Train Accuracy : {:.2f}\".format(accuracy_score(Y_train, train_preds)))\n",
    "print(\"Test  Accuracy : {:.2f}\".format(accuracy_score(Y_test, test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       0.33      1.00      0.50        10\n",
      "\n",
      "    accuracy                           0.33        30\n",
      "   macro avg       0.11      0.33      0.17        30\n",
      "weighted avg       0.11      0.33      0.17        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Test Data Classification Report : \")\n",
    "print(classification_report(Y_test, test_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc07d24e2f18896857f0b2a651fe84ba40ce7b297e58d8804a308c8039f752a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
